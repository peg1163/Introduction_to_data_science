{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Primeros pasos :\n",
    "Haremos los ejercicios dejados en el curso :"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "#@title Define the functions that build and train a model\n",
    "def build_model(my_learning_rate):\n",
    "    \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
    "    # Most simple tf.keras models are sequential.\n",
    "    # A sequential model contains one or more layers.\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Describe the topography of the model.\n",
    "    # The topography of a simple linear regression model\n",
    "    # is a single node in a single layer.\n",
    "    model.add(tf.keras.layers.Dense(units=1,\n",
    "                                    input_shape=(1,)))\n",
    "\n",
    "    # Compile the model topography into code that\n",
    "    # TensorFlow can efficiently execute. Configure\n",
    "    # training to minimize the model's mean squared error.\n",
    "    model.compile(optimizer=tf.keras.optimizers.experimental.RMSprop(learning_rate=my_learning_rate),\n",
    "                  loss=\"mean_squared_error\",\n",
    "                  metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, feature, label, epochs, batch_size):\n",
    "    \"\"\"Train the model by feeding it data.\"\"\"\n",
    "\n",
    "    # Feed the feature values and the label values to the\n",
    "    # model. The model will train for the specified number\n",
    "    # of epochs, gradually learning how the feature values\n",
    "    # relate to the label values.\n",
    "    history = model.fit(x=feature,\n",
    "                        y=label,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs)\n",
    "\n",
    "    # Gather the trained model's weight and bias.\n",
    "    trained_weight = model.get_weights()[0]\n",
    "    trained_bias = model.get_weights()[1]\n",
    "\n",
    "    # The list of epochs is stored separately from the\n",
    "    # rest of history.\n",
    "    epochs = history.epoch\n",
    "\n",
    "    # Gather the history (a snapshot) of each epoch.\n",
    "    hist = pd.DataFrame(history.history)\n",
    "\n",
    "    # Specifically gather the model's root mean\n",
    "    # squared error at each epoch.\n",
    "    rmse = hist[\"root_mean_squared_error\"]\n",
    "\n",
    "    return trained_weight, trained_bias, epochs, rmse\n",
    "\n",
    "print(\"Defined build_model and train_model\")\n",
    "#@title Define the plotting functions\n",
    "def plot_the_model(trained_weight, trained_bias, feature, label):\n",
    "    \"\"\"Plot the trained model against the training feature and label.\"\"\"\n",
    "\n",
    "    # Label the axes.\n",
    "    plt.xlabel(\"feature\")\n",
    "    plt.ylabel(\"label\")\n",
    "\n",
    "    # Plot the feature values vs. label values.\n",
    "    plt.scatter(feature, label)\n",
    "\n",
    "    # Create a red line representing the model. The red line starts\n",
    "    # at coordinates (x0, y0) and ends at coordinates (x1, y1).\n",
    "    x0 = 0\n",
    "    y0 = trained_bias\n",
    "    x1 = feature[-1]\n",
    "    y1 = trained_bias + (trained_weight * x1)\n",
    "    plt.plot([x0, x1], [y0, y1],  c='r')\n",
    "\n",
    "    # Render the scatter plot and the red line.\n",
    "    plt.show()\n",
    "\n",
    "def plot_the_loss_curve(epochs, rmse):\n",
    "    \"\"\"Plot the loss curve, which shows loss vs. epoch.\"\"\"\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Root Mean Squared Error\")\n",
    "\n",
    "    plt.plot(epochs, rmse, label=\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.ylim([rmse.min()*0.97, rmse.max()])\n",
    "    plt.show()\n",
    "\n",
    "print(\"Defined the plot_the_model and plot_the_loss_curve functions.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Resumiendo el codigo , genera un modelo con una neurona con la libreria tensorflow , para poder generar una regresion lineal ,y tambien plotea los puntos a tratar y la recta predicha .Debajo de esto estarian los datos que aplicariamos a la regresion ."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_feature = np.array([1.0, 2.0,  3.0,  4.0,  5.0,  6.0,  7.0,  8.0,  9.0, 10.0, 11.0, 12.0])\n",
    "my_label   = np.array([5.0, 8.8,  9.6, 14.2, 18.8, 19.5, 21.4, 26.8, 28.9, 32.0, 33.8, 38.2])\n",
    "learning_rate=0.01\n",
    "epochs=10\n",
    "my_batch_size=12\n",
    "\n",
    "my_model = build_model(learning_rate)\n",
    "trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature,\n",
    "                                                         my_label, epochs,\n",
    "                                                         my_batch_size)\n",
    "plot_the_model(trained_weight, trained_bias, my_feature, my_label)\n",
    "plot_the_loss_curve(epochs, rmse)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ejercicio 1 :\n",
    "Examine el gráfico superior. Los puntos azules identifican los datos reales; La línea roja identifica la salida del modelo entrenado. Idealmente, la línea roja debe alinearse bien con los puntos azules. ¿Lo hace? Probablemente no.\n",
    "\n",
    "Una cierta cantidad de aleatoriedad juega en el entrenamiento de un modelo, por lo que obtendrá resultados algo diferentes cada vez que entrene. Dicho esto, a menos que seas una persona extremadamente afortunada, la línea roja probablemente no se alinee bien con los puntos azules.\n",
    "\n",
    "Examine el gráfico inferior, que muestra la curva de pérdida. Observe que la curva de pérdida disminuye pero no se aplana, lo cual es una señal de que el modelo no se ha entrenado lo suficiente."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Respuesta :Si ejecutamos el programa tal cual nos lo dan , este no llegaria a tener una prediccion correcta y la recta generada se alejaria a los datos entregados\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ejercicio 2 :\n",
    "La pérdida de entrenamiento debe disminuir constantemente, abruptamente al principio, y luego más lentamente. Eventualmente, la pérdida de entrenamiento debe mantenerse estable (pendiente cero o pendiente casi cero), lo que indica que el entrenamiento ha convergido.\n",
    "\n",
    "En la Tarea 1, la pérdida de entrenamiento no convergió. Una posible solución es entrenar para más épocas. Su tarea es aumentar el número de épocas lo suficiente como para que el modelo converja. Sin embargo, es ineficiente entrenar la convergencia pasada, así que no solo establezca el número de épocas en un valor arbitrariamente alto.\n",
    "\n",
    "Examine la curva de pérdida. ¿Converge el modelo?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Respuesta :Al poner numeros un poco altos al inicial ,comoo 100 o 200 no se llega a la convergencia del modelo , pero si se aumenta hasta un aproximado de 450 - 500 epochs llega a converger el modelo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ejercicio 3 :\n",
    "En la tarea 2, aumentó el número de épocas para que el modelo converja. A veces, puede hacer que el modelo converja más rápidamente aumentando la tasa de aprendizaje. Sin embargo, establecer la tasa de aprendizaje demasiado alta a menudo hace imposible que un modelo converja. En la Tarea 3, hemos establecido intencionalmente la tasa de aprendizaje demasiado alta. Ejecute la siguiente celda de código y vea qué sucede."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "con esa taza de aprendizaje y con esa cantidad de epochs no llega a converger el modelo"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
